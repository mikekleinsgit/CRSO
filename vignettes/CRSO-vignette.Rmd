---
title: "CRSO-vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{CRSO-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette presents an example workflow for CRSO. If a parallel backend is registered, CRSO will make use of all available registered workers. If not, it can still be run sequentially.
```{r setup}
library(crso)
library(foreach)
n.cores <- 1
### Set up parallel backend, example with doMC:
#n.cores <- detectCores()
#library(doMC); registerDoMC(n.cores)

### Load example dataset consisting of TCGA melanoma (SKCM) patients.
data(skcm)
list2env(skcm.list,envir=globalenv())
names(skcm.list) ### load D, P and cnv.dictionary
Q <- log10(P) ### Q is the penalty matrix derived from P
```

# Specify parameters and initialize timing vector
The parameter values used are not the default values that are recommended in the CRSO paper, because the computation time may be excessive depending on the parallel availability. Instead, these were chosen to demonstrate how to use all of the functions in the package. The recommended parameter values are indicated in parentheses.
```{r}
### Coverage parameters
rule.thresh <- .05
msa <- ceiling(ncol(D)*rule.thresh)

### Phase-1 parameters
spr <- 1 # Phase 1 random sets per rule (default = 20, recommend at least 10)
trn <- 30 # Phase 1 stop criteria (default = 24, recommend at most 30)
cut.size <- 0.5 # Fraction of low scoring rules per iteration

### P2 parameters
k.max.2 <- 4
max.nrs.p2 <- 10000 # (default is 200000)
max.compute.p2 <- 5*max.nrs.p2
max.stored.p2 <- 10 # (default is 10)

### P3 parameters
max.nrs.p3 <- 10000 # (default is 200000)
max.stored.p3 <- 10 # (default is 10)

### P4 parameters
k.max.4 <- 8 # default is 40
max.nrs.p4 <- 10000 # max RS per evaluated per next K (default is 100)
max.stored.p4 <- 100

### GC parameters
gc.iter <- 10 # Number GC iterations (default is 100)
gc.eval <- 10 # RS of each K evaluated per GC iteration (default is 100)

r.seed <- 100
set.seed(r.seed)

params.vec <- c(n.cores = n.cores, msa = msa, rule.thresh = rule.thresh,
                spr = spr, trn = trn, cut.size = cut.size,
                k.max.2 = k.max.2, max.nrs.p2 = max.nrs.p2,
                max.stored.p2= max.stored.p2,max.nrs.p3 = max.nrs.p3,
                max.stored.p3 = max.stored.p3,k.max.4 = k.max.4,
                max.nrs.p4 = max.nrs.p4, max.stored.p4 = max.stored.p4,
                gc.iter = gc.iter, gc.eval = gc.eval,r.seed=r.seed)
### initialize timing vect
timing.vec <- rep(NA,length=7)
names(timing.vec) <- c("P1","PS","P2","P3","P4","GC","Total")
```


# Build starting rule library (rm.start), initialize full results list
```{r build rule library}
rm.start <- buildRuleLibrary(D,rule.thresh)
print(paste0("Dimensions of rm start = ",paste0(dim(rm.start),collapse = " ")))
### "Dimensions of rm start = 60 71"
full.results.list <- list(params.vec = params.vec, D = D, P = P, Q = Q,
                          rm.start = rm.start, timing.vec = timing.vec)
```

# Run phase 1
Phase 1 is a stochastic procedure used to rank the rules in rm.start according to contribution to random rule sets
```{r phase 1}
beg <- Sys.time()
print("Starting Phase One")
rm.ordered <- runPhaseOne(D,Q,rm.start,cut.size=cut.size,spr=spr,trn=trn,shouldPrint = TRUE)
timing.vec["P1"] <- signif(difftime(Sys.time(),beg,units="min"),3)

full.results.list[["rm.ordered"]] <- rm.ordered
full.results.list[["timing.vec"]] <- timing.vec
```

# Determine pool sizes for phase 2
The pool size for each K is the number of rules considered for exhaustive evaluation in phase 2.
```{r pool sizes}
beg <- Sys.time()
pool.sizes <- getPoolSizes(rm.ordered,k.max.2,max.nrs.p2,max.compute.p2)
timing.vec["PS"] <- signif(difftime(Sys.time(),beg,units="min"),3)

full.results.list[["pool.sizes"]] <- pool.sizes
full.results.list[["timing.vec"]] <- timing.vec
print(paste0("Pool Sizes = ",paste0(pool.sizes,collapse = " ")))
print(paste0("Timing Vec = ",paste0(timing.vec,collapse = " ")))
```


# Phase 2
Phase 2 performans exhaustive evaluation over of top pool_sizes(k) rules for each k. The output of phase 2 is a list of top index matrices for each k (p2.iml = p2 index matrix list).  Each index matrix contains the rule sets ordered by performance. For example the best performing rule set of size 3 will be the first row of the K.3 index matrix. For K=1 the index matrix is a vector.
```{r phase 2}
print("Starting Phase Two")
beg <- Sys.time()
p2.iml <- makePhaseTwoImList(D,Q,rm.ordered,pool.sizes,
                             max.stored.p2,msa,shouldPrint = TRUE)
timing.vec["P2"] <- signif(difftime(Sys.time(),beg,units="min"),3)
print(paste0("Timing Vec = ",paste0(timing.vec,collapse = " ")))
full.results.list[["p2.iml"]] <- p2.iml
full.results.list[["timing.vec"]] <- timing.vec

### Extra optional step to look at the best performances after phase 2
p2.pl <- evaluateListOfIMs(D,Q,rm.ordered,p2.iml,msa)
p2.best.perfs <- signif(unlist(lapply(p2.pl,max)),5)
print(paste0("P2 Best Perfs = ",paste0(p2.best.perfs,collapse = " ")))
```

# Phase 3 
```{r phase 3}
### P3 ###############################################################
print("Starting Phase Three")
beg <- Sys.time()
fm.ordered <- getFamMat(rm.ordered)
p3.iml <- makePhaseThreeImList(D, Q, rm.ordered, fm.ordered, p2.iml, 
                               pool.sizes, max.stored.p3, 
                               max.nrs.p3, msa, shouldPrint = TRUE)
p3.pl <- evaluateListOfIMs(D,Q,rm.ordered,p3.iml,msa) 
p3.best.perfs <- signif(unlist(lapply(p3.pl,max)),5)
timing.vec["P3"] <- signif(difftime(Sys.time(),beg,units="min"),3)
full.results.list[["p3.iml"]] <- p3.iml
full.results.list[["timing.vec"]] <- timing.vec
print(paste0("P3 Best Perfs = ",paste0(p3.best.perfs,collapse = " ")))
print(paste0("Timing Vec = ",paste0(timing.vec,collapse = " ")))
```

# Extract best rule sets and core rule set
```{r phase4}

```

# Extract best rule sets and core rule set
```{r get core}

```

# Make generalized core results
```{r gen core}
# list.subset.cores <- makeSubCoreList(D,Q,rm.ordered,til.filtered,num.gc.iter,num.gc.eval)
# ### list.subset.cores is a list of core rule set derived from subsampling iterations
# 
# gcr.df <- getGCRs(list.subset.cores) # Generalized core rules
# print(gcr.df)
# gcd.df <- getGCDs(list.subset.cores) # Generalized core duos
# print(gcd.df)
# gce.df <- getGCEs(list.subset.cores) # Generalized core events
# print(gce.df)
```

